#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡åˆ›å»ºé…ç½®æ–‡ä»¶
è‡ªåŠ¨æ‰«ædataç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶ï¼Œä¸ºæ¯ä¸ªæ•°æ®é›†ç”Ÿæˆå¯¹åº”çš„é…ç½®æ–‡ä»¶
"""

import os
import glob
import yaml
import pandas as pd
from pathlib import Path
import re

def extract_plant_id(filename):
    """
    ä»æ–‡ä»¶åä¸­æå–ç”µç«™ID
    æ”¯æŒæ ¼å¼ï¼šProject1140.csv, Plant1140.csv, 1140.csvç­‰
    """
    basename = os.path.basename(filename)
    
    # å°è¯•å¤šç§æ¨¡å¼
    patterns = [
        r'Project(\d+)',
        r'Plant(\d+)',
        r'plant(\d+)',
        r'project(\d+)',
        r'^(\d+)',  # çº¯æ•°å­—å¼€å¤´
    ]
    
    for pattern in patterns:
        match = re.search(pattern, basename, re.IGNORECASE)
        if match:
            return match.group(1)
    
    # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œä½¿ç”¨æ–‡ä»¶åï¼ˆå»é™¤æ‰©å±•åï¼‰
    return basename.replace('.csv', '').replace('.CSV', '')

def detect_date_range(csv_file):
    """
    è‡ªåŠ¨æ£€æµ‹æ•°æ®é›†çš„æ—¶é—´èŒƒå›´
    """
    try:
        # è¯»å–CSVæ–‡ä»¶ï¼ˆåªè¯»å–å‰å‡ è¡Œå’Œæœ€åå‡ è¡Œæ¥èŠ‚çœæ—¶é—´ï¼‰
        df_head = pd.read_csv(csv_file, nrows=10)
        df = pd.read_csv(csv_file)
        
        # å°è¯•æ„å»ºæ—¥æœŸæ—¶é—´
        if all(col in df.columns for col in ['Year', 'Month', 'Day', 'Hour']):
            df['Datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour']])
            start_date = df['Datetime'].min().strftime('%Y-%m-%d')
            end_date = df['Datetime'].max().strftime('%Y-%m-%d')
            return start_date, end_date, len(df)
        else:
            print(f"  âš ï¸  è­¦å‘Š: {csv_file} ç¼ºå°‘å¿…è¦çš„æ—¶é—´åˆ—ï¼Œä½¿ç”¨é»˜è®¤æ—¥æœŸ")
            return '2022-01-01', '2024-09-28', len(df)
    except Exception as e:
        print(f"  âš ï¸  è¯»å– {csv_file} æ—¶å‡ºé”™: {str(e)}")
        return '2022-01-01', '2024-09-28', 0

def create_plant_config(csv_file, template_path='config/plant_template.yaml'):
    """
    ä¸ºå•ä¸ªæ•°æ®é›†åˆ›å»ºé…ç½®æ–‡ä»¶
    """
    # è¯»å–æ¨¡æ¿
    with open(template_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æå–ç”µç«™ID
    plant_id = extract_plant_id(csv_file)
    
    # æ£€æµ‹æ—¥æœŸèŒƒå›´
    start_date, end_date, data_length = detect_date_range(csv_file)
    
    # æ›´æ–°é…ç½®
    config['plant_id'] = str(plant_id)
    config['plant_name'] = f"Project {plant_id}"
    config['data_path'] = csv_file
    config['start_date'] = start_date
    config['end_date'] = end_date
    
    # ä¿ç•™æ¨¡æ¿ä¸­çš„å…¶ä»–é»˜è®¤è®¾ç½®
    # shuffle_splité»˜è®¤ä¸ºFalse (Sequentialåˆ’åˆ†)
    if 'shuffle_split' not in config:
        config['shuffle_split'] = False
    if 'random_seed' not in config:
        config['random_seed'] = 42
    if 'past_hours' not in config:
        config['past_hours'] = 24
    
    return plant_id, config, data_length

def batch_create_configs(data_dir='data', output_dir='config/plants', template='config/plant_template.yaml'):
    """
    æ‰¹é‡åˆ›å»ºé…ç½®æ–‡ä»¶
    """
    print("="*80)
    print("æ‰¹é‡åˆ›å»ºé…ç½®æ–‡ä»¶")
    print("="*80)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # æŸ¥æ‰¾æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = glob.glob(os.path.join(data_dir, '*.csv')) + glob.glob(os.path.join(data_dir, '*.CSV'))
    
    if not csv_files:
        print(f"\nâŒ é”™è¯¯: åœ¨ {data_dir} ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°CSVæ–‡ä»¶")
        print(f"è¯·ç¡®ä¿æ•°æ®é›†æ–‡ä»¶å·²æ”¾ç½®åœ¨ {data_dir} ç›®å½•ä¸­")
        return
    
    print(f"\næ‰¾åˆ° {len(csv_files)} ä¸ªæ•°æ®é›†æ–‡ä»¶")
    print("-"*80)
    
    created_configs = []
    skipped_configs = []
    
    for i, csv_file in enumerate(csv_files, 1):
        filename = os.path.basename(csv_file)
        print(f"\n[{i}/{len(csv_files)}] å¤„ç†: {filename}")
        
        try:
            # åˆ›å»ºé…ç½®
            plant_id, config, data_length = create_plant_config(csv_file, template)
            
            # ä¿å­˜é…ç½®æ–‡ä»¶
            config_file = os.path.join(output_dir, f'Plant{plant_id}.yaml')
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if os.path.exists(config_file):
                print(f"  âš ï¸  é…ç½®æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {config_file}")
                skipped_configs.append(plant_id)
                continue
            
            with open(config_file, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
            
            print(f"  âœ“ åˆ›å»ºé…ç½®: {config_file}")
            print(f"    ç”µç«™ID: {plant_id}")
            print(f"    æ•°æ®èŒƒå›´: {config['start_date']} è‡³ {config['end_date']}")
            print(f"    æ•°æ®é‡: {data_length} æ¡è®°å½•")
            
            created_configs.append(plant_id)
            
        except Exception as e:
            print(f"  âŒ é”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")
    print("="*80)
    print(f"âœ“ æ–°åˆ›å»º: {len(created_configs)} ä¸ªé…ç½®æ–‡ä»¶")
    print(f"âš ï¸ å·²è·³è¿‡: {len(skipped_configs)} ä¸ªé…ç½®æ–‡ä»¶ï¼ˆå·²å­˜åœ¨ï¼‰")
    print(f"ğŸ“ é…ç½®ç›®å½•: {output_dir}")
    
    if created_configs:
        print(f"\nåˆ›å»ºçš„ç”µç«™ID: {', '.join(created_configs[:10])}" + 
              (f" ... (å…±{len(created_configs)}ä¸ª)" if len(created_configs) > 10 else ""))
    
    print("\nä¸‹ä¸€æ­¥:")
    print("  1. æ£€æŸ¥é…ç½®æ–‡ä»¶: ls config/plants/")
    print("  2. è¿è¡Œå•ä¸ªç”µç«™æµ‹è¯•: python run_all_experiments.py")
    print("  3. è¿è¡Œæ‰€æœ‰ç”µç«™: python run_experiments_multi_plant.py")
    print("="*80)

def verify_configs(config_dir='config/plants'):
    """
    éªŒè¯æ‰€æœ‰é…ç½®æ–‡ä»¶
    """
    print("\néªŒè¯é…ç½®æ–‡ä»¶...")
    config_files = glob.glob(os.path.join(config_dir, '*.yaml'))
    
    valid_count = 0
    invalid_count = 0
    
    for config_file in config_files:
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['plant_id', 'data_path', 'start_date', 'end_date']
            missing_fields = [field for field in required_fields if field not in config]
            
            if missing_fields:
                print(f"  âš ï¸  {os.path.basename(config_file)}: ç¼ºå°‘å­—æ®µ {missing_fields}")
                invalid_count += 1
            else:
                # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(config['data_path']):
                    print(f"  âš ï¸  {os.path.basename(config_file)}: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ {config['data_path']}")
                    invalid_count += 1
                else:
                    valid_count += 1
        except Exception as e:
            print(f"  âŒ {os.path.basename(config_file)}: {str(e)}")
            invalid_count += 1
    
    print(f"\néªŒè¯ç»“æœ: âœ“ {valid_count} ä¸ªæœ‰æ•ˆ, âš ï¸ {invalid_count} ä¸ªæ— æ•ˆ")
    return valid_count, invalid_count

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='æ‰¹é‡åˆ›å»ºé…ç½®æ–‡ä»¶')
    parser.add_argument('--data-dir', default='data', help='æ•°æ®é›†ç›®å½• (é»˜è®¤: data)')
    parser.add_argument('--output-dir', default='config/plants', help='é…ç½®è¾“å‡ºç›®å½• (é»˜è®¤: config/plants)')
    parser.add_argument('--template', default='config/plant_template.yaml', help='é…ç½®æ¨¡æ¿æ–‡ä»¶')
    parser.add_argument('--verify', action='store_true', help='éªŒè¯å·²åˆ›å»ºçš„é…ç½®æ–‡ä»¶')
    parser.add_argument('--force', action='store_true', help='å¼ºåˆ¶è¦†ç›–å·²å­˜åœ¨çš„é…ç½®æ–‡ä»¶')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.template):
        print(f"âŒ é”™è¯¯: æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {args.template}")
        exit(1)
    
    # å¦‚æœåªæ˜¯éªŒè¯
    if args.verify:
        verify_configs(args.output_dir)
        exit(0)
    
    # æ‰¹é‡åˆ›å»ºé…ç½®
    batch_create_configs(args.data_dir, args.output_dir, args.template)
    
    # éªŒè¯åˆ›å»ºçš„é…ç½®
    print("\n")
    verify_configs(args.output_dir)

