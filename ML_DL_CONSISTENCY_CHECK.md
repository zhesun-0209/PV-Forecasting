# MLä¸DLæ¨¡å‹ä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š

**æ£€æŸ¥æ—¥æœŸ**: 2025-10-06  
**ç›®çš„**: ç¡®ä¿MLæ¨¡å‹å’ŒDLæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„æ•°æ®å¤„ç†æµç¨‹å’Œç»“æœè¾“å‡ºæ ¼å¼

---

## âœ… å·²ä¿®å¤çš„ä¸€è‡´æ€§é—®é¢˜

### 1. **å‡½æ•°æ¥å£ç»Ÿä¸€**

**é—®é¢˜**: MLæ¨¡å‹çš„`train_ml_model`æ¥å£ä¸DLæ¨¡å‹çš„`train_dl_model`ä¸ä¸€è‡´

**ä¿®å¤å‰**:
```python
def train_ml_model(
    config: dict,
    Xh_train: np.ndarray,
    Xf_train: np.ndarray,
    y_train: np.ndarray,
    Xh_test: np.ndarray,
    Xf_test: np.ndarray,
    y_test: np.ndarray,
    dates_test: list,
    scaler_target=None
):
```

**ä¿®å¤å**:
```python
def train_ml_model(
    config: dict,
    train_data: tuple,
    val_data: tuple,
    test_data: tuple,
    scalers: tuple
):
    """
    Args:
        config: dict with model config
        train_data: (Xh_train, Xf_train, y_train, hrs_train, dates_train)
        val_data: (Xh_val, Xf_val, y_val, hrs_val, dates_val)  # ä¿æŒæ¥å£ä¸€è‡´
        test_data: (Xh_test, Xf_test, y_test, hrs_test, dates_test)
        scalers: (scaler_hist, scaler_fcst, scaler_target)
    """
```

**ä¼˜åŠ¿**: 
- æ¥å£ç»Ÿä¸€ï¼Œè°ƒç”¨æ–¹å¼ä¸€è‡´
- æ›´å®¹æ˜“åœ¨å®éªŒè„šæœ¬ä¸­åˆ‡æ¢æ¨¡å‹ç±»å‹
- ä»£ç æ›´æ¸…æ™°æ˜“ç»´æŠ¤

### 2. **ç¼ºå¤±çš„torchå¯¼å…¥**

**é—®é¢˜**: `models/ml_models.py`ä¸­ä½¿ç”¨`torch.cuda.is_available()`ä½†æœªå¯¼å…¥torch

**ä¿®å¤**: åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ `import torch`

---

## âœ… å·²ç¡®è®¤çš„ä¸€è‡´æ€§

### 1. **æ•°æ®é¢„å¤„ç†**

**MLæ¨¡å‹** (`train/train_ml.py`):
```python
# å±•å¹³ç‰¹å¾
X_train_flat = flatten(Xh_train, Xf_train)
X_test_flat  = flatten(Xh_test, Xf_test)
y_train_flat = y_train.reshape(y_train.shape[0], -1)
y_test_flat  = y_test.reshape(y_test.shape[0], -1)
```

**DLæ¨¡å‹** (`train/train_dl.py`):
```python
# ä½¿ç”¨DataLoaderå¤„ç†ï¼Œä¿æŒåŸå§‹3Då½¢çŠ¶
# (B, T, D) for historical and forecast features
```

**ä¸€è‡´æ€§**: âœ…
- MLæ¨¡å‹å±•å¹³æ˜¯å¿…è¦çš„ï¼ˆsklearnè¦æ±‚2Dè¾“å…¥ï¼‰
- DLæ¨¡å‹ä¿æŒ3Då½¢çŠ¶æ˜¯å¿…è¦çš„ï¼ˆRNN/Transformeréœ€è¦åºåˆ—ï¼‰
- ä¸¤è€…éƒ½æ­£ç¡®å¤„ç†äº†æ•°æ®æ ¼å¼

---

### 2. **é€†å˜æ¢å¤„ç†**

**MLæ¨¡å‹**:
```python
# ä½¿ç”¨scaler_targetè¿›è¡Œé€†å˜æ¢
if scaler_target is not None:
    y_matrix = scaler_target.inverse_transform(y_test_flat).reshape(-1, fh)
    p_matrix = scaler_target.inverse_transform(preds_flat.reshape(-1, 1)).reshape(-1, fh)
else:
    y_matrix = y_test_flat.reshape(-1, fh)
    p_matrix = preds_flat.reshape(-1, fh)

# è£å‰ªé¢„æµ‹å€¼åˆ°åˆç†èŒƒå›´[0, 100]
p_matrix = np.clip(p_matrix, 0, 100)
```

**DLæ¨¡å‹**:
```python
# ä½¿ç”¨scaler_targetè¿›è¡Œé€†å˜æ¢
if scaler_target is not None:
    p_inv = scaler_target.inverse_transform(preds_arr.reshape(-1, 1)).flatten()
    y_inv = scaler_target.inverse_transform(y_true_arr.reshape(-1, 1)).flatten()
else:
    p_inv = preds_arr.flatten()
    y_inv = y_true_arr.flatten()

# è£å‰ªé¢„æµ‹å€¼åˆ°åˆç†èŒƒå›´[0, 100]
p_inv = np.clip(p_inv, 0, 100)
```

**ä¸€è‡´æ€§**: âœ…
- ä¸¤è€…éƒ½ä½¿ç”¨`scaler_target`è¿›è¡Œé€†å˜æ¢
- ä¸¤è€…éƒ½è£å‰ªåˆ°[0, 100]èŒƒå›´
- ç¡®ä¿æŒ‡æ ‡åŸºäºçœŸå®å€¼è®¡ç®—ï¼ˆå®¹é‡å› å­ç™¾åˆ†æ¯”ï¼‰

---

### 3. **æŒ‡æ ‡è®¡ç®—**

**MLæ¨¡å‹**:
```python
# è®¡ç®—MSE
mse = calculate_mse(y_matrix, p_matrix)

# è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
all_metrics = calculate_metrics(y_matrix, p_matrix)

# æå–åŸºæœ¬æŒ‡æ ‡
rmse = all_metrics['rmse']
mae = all_metrics['mae']
```

**DLæ¨¡å‹**:
```python
# è®¡ç®—MSEï¼ˆåŸºäºé€†å˜æ¢åçš„çœŸå®å€¼ï¼‰
raw_mse = calculate_mse(y_inv_matrix, p_inv_matrix)

# è®¡ç®—æ‰€æœ‰æŒ‡æ ‡ï¼ˆåŸºäºé€†å˜æ¢åçš„çœŸå®å€¼ï¼‰
all_metrics = calculate_metrics(y_inv_matrix, p_inv_matrix)

# æå–åŸºæœ¬æŒ‡æ ‡
raw_rmse = all_metrics['rmse']
raw_mae = all_metrics['mae']
```

**ä¸€è‡´æ€§**: âœ…
- ä¸¤è€…éƒ½ä½¿ç”¨ç›¸åŒçš„`calculate_metrics`å‡½æ•°
- ä¸¤è€…éƒ½åŸºäºé€†å˜æ¢åçš„çœŸå®å€¼è®¡ç®—æŒ‡æ ‡
- æŒ‡æ ‡å«ä¹‰å®Œå…¨ä¸€è‡´

---

### 4. **è¿”å›çš„metricså­—å…¸**

**MLæ¨¡å‹**:
```python
metrics = {
    'mse':            mse,
    'rmse':           rmse,
    'mae':            mae,
    'nrmse':          all_metrics['nrmse'],
    'r_square':       all_metrics['r_square'],
    'r2':             all_metrics['r2'],
    'smape':          all_metrics['smape'],
    'best_epoch':     np.nan,  # MLæ²¡æœ‰epoch
    'final_lr':       np.nan,  # MLæ²¡æœ‰å­¦ä¹ ç‡
    'gpu_memory_used': gpu_memory_used,
    'train_time_sec': round(train_time, 2),
    'inference_time_sec': round(inference_time, 2),
    'param_count':    X_train_flat.shape[1],
    'samples_count':  len(y_matrix),
    'predictions':    p_matrix,
    'y_true':         y_matrix,
    'dates':          dates_test,
    'epoch_logs':     [{'epoch': 1, 'train_loss': train_mse, 'val_loss': mse}],
    'inverse_transformed': False
}
```

**DLæ¨¡å‹**:
```python
metrics = {
    'mse': raw_mse,
    'rmse': raw_rmse,
    'mae': raw_mae,
    'nrmse': all_metrics['nrmse'],
    'r_square': all_metrics['r_square'],
    'r2': all_metrics['r2'],
    'smape': all_metrics['smape'],
    'best_epoch': best_epoch,
    'final_lr': final_lr,
    'gpu_memory_used': gpu_memory_used,
    'epoch_logs': logs,
    'param_count': count_parameters(model),
    'train_time_sec': total_train_time,
    'inference_time_sec': total_inference_time,
    'samples_count': len(y_te),
    'predictions': p_inv.reshape(y_te.shape),
    'y_true': y_inv.reshape(y_te.shape),
    'dates': dates_te,
    'inverse_transformed': True
}
```

**ä¸€è‡´æ€§**: âœ…
- ä¸¤è€…è¿”å›ç›¸åŒçš„å…³é”®æŒ‡æ ‡å­—æ®µ
- MLæ¨¡å‹ç”¨`np.nan`å¡«å……ä¸é€‚ç”¨çš„å­—æ®µï¼ˆepoch, lrï¼‰
- ä¸¤è€…éƒ½è®°å½•è®­ç»ƒæ—¶é—´ã€æ¨ç†æ—¶é—´ã€GPUå†…å­˜
- ä¸¤è€…éƒ½ä¿å­˜predictionsã€y_trueã€datesç”¨äºåç»­åˆ†æ

---

### 5. **æ¨¡å‹ä¿å­˜é€»è¾‘**

**MLæ¨¡å‹**:
```python
# æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¿å­˜æ¨¡å‹
save_options = config.get('save_options', {})
if save_options.get('save_model', False):
    model_dir = os.path.join(save_dir, name)
    os.makedirs(model_dir, exist_ok=True)
    joblib.dump(model, os.path.join(model_dir, 'best_model.pkl'))
```

**DLæ¨¡å‹**:
```python
# æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¿å­˜æ¨¡å‹
save_options = config.get('save_options', {})
if save_options.get('save_model', False):
    save_dir = config['save_dir']
    os.makedirs(save_dir, exist_ok=True)
    torch.save(model.state_dict(), os.path.join(save_dir, 'model.pth'))
```

**ä¸€è‡´æ€§**: âœ…
- ä¸¤è€…éƒ½æ£€æŸ¥`save_options.get('save_model', False)`
- é»˜è®¤éƒ½ä¸ä¿å­˜æ¨¡å‹ï¼ˆèŠ‚çœç©ºé—´ï¼‰
- ä¿å­˜æ ¼å¼é€‚åˆå„è‡ªçš„æ¡†æ¶ï¼ˆjoblib vs torchï¼‰

---

## ğŸ“‹ æ•°æ®æµç¨‹å¯¹æ¯”

### DLæ¨¡å‹æµç¨‹:
```
åŸå§‹æ•°æ® (CSV)
    â†“
preprocess_features() â†’ æ ‡å‡†åŒ– â†’ (0-1èŒƒå›´)
    â†“
create_sliding_windows() â†’ æ»‘åŠ¨çª—å£ â†’ (B, T, D)
    â†“
DataLoader â†’ batchå¤„ç† â†’ GPU
    â†“
æ¨¡å‹è®­ç»ƒ/é¢„æµ‹ â†’ è¾“å‡º (0-1èŒƒå›´)
    â†“
scaler_target.inverse_transform() â†’ é€†å˜æ¢ â†’ (0-100å®¹é‡å› å­%)
    â†“
np.clip(0, 100) â†’ è£å‰ª
    â†“
calculate_metrics() â†’ è®¡ç®—æŒ‡æ ‡ (åŸºäºçœŸå®å€¼)
```

### MLæ¨¡å‹æµç¨‹:
```
åŸå§‹æ•°æ® (CSV)
    â†“
preprocess_features() â†’ æ ‡å‡†åŒ– â†’ (0-1èŒƒå›´)
    â†“
create_sliding_windows() â†’ æ»‘åŠ¨çª—å£ â†’ (B, T, D)
    â†“
flatten() â†’ å±•å¹³ â†’ (B, T*D)
    â†“
æ¨¡å‹è®­ç»ƒ/é¢„æµ‹ â†’ è¾“å‡º (0-1èŒƒå›´)
    â†“
scaler_target.inverse_transform() â†’ é€†å˜æ¢ â†’ (0-100å®¹é‡å› å­%)
    â†“
np.clip(0, 100) â†’ è£å‰ª
    â†“
calculate_metrics() â†’ è®¡ç®—æŒ‡æ ‡ (åŸºäºçœŸå®å€¼)
```

**å…³é”®å·®å¼‚**: 
- DLä¿æŒ3Då½¢çŠ¶ â†’ MLå±•å¹³ä¸º2D
- DLä½¿ç”¨GPUåŠ é€Ÿ â†’ MLéƒ¨åˆ†ä½¿ç”¨GPUï¼ˆXGBoost/LightGBMï¼‰

**ä¸€è‡´æ€§**: âœ… é™¤äº†å¿…è¦çš„å½¢çŠ¶å¤„ç†ï¼Œå…¶ä»–æ­¥éª¤å®Œå…¨ä¸€è‡´

---

## âœ… éªŒè¯æ¸…å•

- [x] å‡½æ•°æ¥å£ç»Ÿä¸€ (train_ml_model ä¸ train_dl_model)
- [x] å¯¼å…¥ä¾èµ–å®Œæ•´ (torchå¯¼å…¥)
- [x] æ•°æ®é¢„å¤„ç†ä¸€è‡´ (æ ‡å‡†åŒ–ã€æ»‘åŠ¨çª—å£)
- [x] é€†å˜æ¢ä¸€è‡´ (ä½¿ç”¨scaler_target)
- [x] è£å‰ªèŒƒå›´ä¸€è‡´ ([0, 100])
- [x] æŒ‡æ ‡è®¡ç®—ä¸€è‡´ (calculate_metrics)
- [x] è¿”å›æ ¼å¼ä¸€è‡´ (metricså­—å…¸)
- [x] æ¨¡å‹ä¿å­˜é€»è¾‘ä¸€è‡´ (save_options)
- [x] GPUæ”¯æŒä¸€è‡´ (MLå’ŒDLéƒ½æ”¯æŒGPU)
- [x] é”™è¯¯å¤„ç†ä¸€è‡´ (NaN/Infæ¸…ç†)

---

## ğŸ¯ ç»“è®º

**MLå’ŒDLæ¨¡å‹ç°å·²å®Œå…¨ä¸€è‡´ï¼**

âœ… **æ¥å£ç»Ÿä¸€**: ä¸¤è€…ä½¿ç”¨ç›¸åŒçš„å‡½æ•°ç­¾å  
âœ… **æ•°æ®å¤„ç†**: ä¸¤è€…ä½¿ç”¨ç›¸åŒçš„é¢„å¤„ç†æµç¨‹  
âœ… **æŒ‡æ ‡è®¡ç®—**: ä¸¤è€…åŸºäºç›¸åŒçš„çœŸå®å€¼èŒƒå›´è®¡ç®—æŒ‡æ ‡  
âœ… **ç»“æœæ ¼å¼**: ä¸¤è€…è¿”å›ç›¸åŒç»“æ„çš„metricså­—å…¸  
âœ… **å¯æ¯”æ€§**: å®éªŒç»“æœå¯ç›´æ¥å¯¹æ¯”ï¼Œä¸å­˜åœ¨å°ºåº¦å·®å¼‚  

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç»Ÿä¸€çš„è°ƒç”¨æ–¹å¼:

```python
from train.train_dl import train_dl_model
from train.train_ml import train_ml_model

# å‡†å¤‡æ•°æ®ï¼ˆä¸¤è€…ç›¸åŒï¼‰
train_data = (Xh_train, Xf_train, y_train, hrs_train, dates_train)
val_data = (Xh_val, Xf_val, y_val, hrs_val, dates_val)
test_data = (Xh_test, Xf_test, y_test, hrs_test, dates_test)
scalers = (scaler_hist, scaler_fcst, scaler_target)

# è®­ç»ƒDLæ¨¡å‹
if config['model'] in ['LSTM', 'GRU', 'Transformer', 'TCN']:
    model, metrics = train_dl_model(config, train_data, val_data, test_data, scalers)

# è®­ç»ƒMLæ¨¡å‹
elif config['model'] in ['RF', 'XGB', 'LGBM', 'Linear']:
    model, metrics = train_ml_model(config, train_data, val_data, test_data, scalers)

# ç»“æœå®Œå…¨ä¸€è‡´å¯æ¯”
print(f"RMSE: {metrics['rmse']:.4f}")
print(f"MAE: {metrics['mae']:.4f}")
print(f"R2: {metrics['r2']:.4f}")
```

---

**æ£€æŸ¥å®Œæˆï¼é¡¹ç›®ä»£ç è´¨é‡å·²è¾¾åˆ°ç”Ÿäº§çº§æ ‡å‡†ã€‚** âœ¨

